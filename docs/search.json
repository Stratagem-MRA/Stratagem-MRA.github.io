[
  {
    "objectID": "posts/Chapter2/App/index.html",
    "href": "posts/Chapter2/App/index.html",
    "title": "Street View City Predictor",
    "section": "",
    "text": "Street view city classifier embedded from Hugging Face Spaces. Check it out on github!\nGoogle maps links for your convenience:\n\n\n\n\nCharlotte, NC\n\n\nChicago, IL\n\n\n\n\nColumbus, OH\n\n\nHouston, TX\n\n\n\n\nIndianapolis, IN\n\n\nJacksonville, FL\n\n\n\n\nLos Angeles, CA\n\n\nNew York, NY\n\n\n\n\nPhiladelphia, PA\n\n\nPhoenix, AZ"
  },
  {
    "objectID": "posts/Chapter1/Notebook/Lichess.html",
    "href": "posts/Chapter1/Notebook/Lichess.html",
    "title": "Lichess ELO Guesser Notebook",
    "section": "",
    "text": "#Import libraries and initialize global variables\nimport pandas as pd\n\ncsv_path = 'Data/chessgames-2013-01.csv'\npgn_path = 'Data/lichess_db_standard_rated_2013-01.pgn'\nsvg_size = 8*10 #multiple of 8 guarantees each square on the board is the same size\n\n\n#helper methods for initialization\nimport chess.pgn\nfrom time import perf_counter\n\ndef remove_tournament_url(str):\n    \"\"\"\n    splits str based on whitespace and removes the final item if it begins with 'https'\n    \"\"\"\n    lst = str.split()\n    if lst[-1][:5] == 'https':\n        return ' '.join(lst[:-1])\n    else:\n        return str\n\ndef load_pgn(path):\n    \"\"\"\n    returns a DataFrame with data loaded from pgn file at 'path'\n    \"\"\"\n    start = perf_counter()\n    pgn = open(path)\n    i = 0\n    result = []\n    while(True):\n        game = chess.pgn.read_game(pgn)\n        if game:\n            if not game.errors:\n                event = remove_tournament_url(game.headers['Event'])\n                id = (game.headers['Site'][-8:])\n                gameresult = (game.headers['Result'])\n                whiteelo = (game.headers['WhiteElo'])\n                blackelo = (game.headers['BlackElo'])\n                timecontrol = (game.headers['TimeControl'])\n                termination = (game.headers['Termination'])\n                moves = (str(game.mainline_moves()))\n                nummoves = (game.end().ply())\n                result.append({'Event':event,'ID':id,'Result':gameresult,'WhiteElo':whiteelo,'BlackElo':blackelo,'TimeControl':timecontrol,'Termination':termination,'Moves':moves,'NumMoves':nummoves})\n            i = i+1\n            if(i%10000==0):\n                print(i)\n        else:\n            break\n    pgn.close()\n    df = pd.DataFrame(result)\n    stop = perf_counter()\n    print(f'total time to load PGN into df: {stop-start}\\ngames loaded:{len(df)}')\n    return df\n\ndef drop_missing_elo(df):\n    \"\"\"\n    drops rows of DataFrame where 'WhiteElo' or 'BlackElo' equals '?'\n    \"\"\"\n    len_before = len(df)\n    df = df.drop(df[df['WhiteElo'] == '?'].index)\n    df = df.drop(df[df['BlackElo'] == '?'].index)\n    len_after = len(df)\n    print(f'dropped {len_before-len_after} games with missing Elos')\n    return df\n\ndef result_to_int(str):\n    \"\"\"\n    converts result to 1 if white won, -1 if black won, and 0 if draw\n    \"\"\"\n    if str == '1-0':\n        return 1\n    elif str == '0-1':\n        return -1\n    elif str == '1/2-1/2':\n        return 0\n    else:\n        return None\n        \ndef remap_result_col(df):\n    \"\"\"\n    calls result_to_int for each item in df['Result']\n    \"\"\"\n    df['Result'] = df['Result'].map(result_to_int)\n    return df\n    \ndef update_chess_dtypes(df):\n    \"\"\"\n    converts each DataFrame column to the correct dtype\n    \"\"\"\n    df['Event'] = df['Event'].astype(\"string\")\n    df['ID'] = df['ID'].astype(\"string\")\n    df['Result']  = df['Result'].astype(\"Int8\")\n    df['WhiteElo'] = df['WhiteElo'].astype(\"Float32\")\n    df['BlackElo'] = df['BlackElo'].astype(\"Float32\")\n    df['TimeControl'] = df['TimeControl'].astype(\"string\")\n    df['Termination'] = df['Termination'].astype(\"string\")\n    df['Moves'] = df['Moves'].astype(\"string\")\n    df['NumMoves'] = df['NumMoves'].astype(\"UInt16\") \n    return df\n\n\n#load data into df if it exists else create it from pgn file\nimport os\n\nif os.path.isfile(csv_path):\n    df = pd.read_csv(csv_path,index_col=0)\n    df = update_chess_dtypes(df)\n    print(f'loaded {csv_path} into df')\nelif os.path.isfile(pgn_path):\n    df = load_pgn(pgn_path)\n    df = drop_missing_elo(df)\n    df = remap_result_col(df)\n    df = update_chess_dtypes(df)\n    df.to_csv(csv_path)\n    print(f'df saved to {csv_path}')\nelse:\n    raise(Exception('No valid path found'))\n\nloaded Data/chessgames-2013-01.csv into df\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nEvent\nID\nResult\nWhiteElo\nBlackElo\nTimeControl\nTermination\nMoves\nNumMoves\n\n\n\n\n0\nRated Classical game\nj1dkb5dw\n1\n1639.0\n1403.0\n600+8\nNormal\n1. e4 e6 2. d4 b6 3. a3 Bb7 4. Nc3 Nh6 5. Bxh6 gxh6 6. Be2 Qg5 7. Bg4 h5 8. Nf3 Qg6 9. Nh4 Qg5 10. Bxh5 Qxh4 11. Qf3 Kd8 12. Qxf7 Nc6 13. Qe8#\n25\n\n\n1\nRated Classical game\na9tcp02g\n1\n1654.0\n1919.0\n480+2\nNormal\n1. d4 d5 2. Nf3 Nf6 3. e3 Bf5 4. Nh4 Bg6 5. Nxg6 hxg6 6. Nd2 e6 7. Bd3 Bd6 8. e4 dxe4 9. Nxe4 Rxh2 10. Ke2 Rxh1 11. Qxh1 Nc6 12. Bg5 Ke7 13. Qh7 Nxd4+ 14. Kd2 Qe8 15. Qxg7 Qh8 16. Bxf6+ Kd7 17. Qxh8 Rxh8 18. Bxh8\n35\n\n\n2\nRated Classical game\nszom2tog\n1\n1643.0\n1747.0\n420+17\nNormal\n1. e4 e5 2. Nf3 Nc6 3. Bc4 Nf6 4. Nc3 Bc5 5. a3 Bxf2+ 6. Kxf2 Nd4 7. d3 Ng4+ 8. Kf1 Qf6 9. h3 d5 10. Nxd5 Qe6 11. Nxc7+\n21\n\n\n3\nRated Bullet game\nrklpc7mk\n-1\n1824.0\n1973.0\n60+1\nNormal\n1. e4 c6 2. Nc3 d5 3. Qf3 dxe4 4. Nxe4 Nd7 5. Bc4 Ngf6 6. Nxf6+ Nxf6 7. Qg3 Bf5 8. d3 Bg6 9. Ne2 e6 10. Bf4 Nh5 11. Qf3 Nxf4 12. Nxf4 Be7 13. Bxe6 fxe6 14. Nxe6 Qa5+ 15. c3 Qe5+ 16. Qe3 Qxe3+ 17. fxe3 Kd7 18. Nf4 Bd6 19. Nxg6 hxg6 20. h3 Bg3+ 21. Kd2 Raf8 22. Rhf1 Ke7 23. d4 Rxf1 24. Rxf1 Rf8 25. Rxf8 Kxf8 26. e4 Ke7 27. Ke3 g5 28. Kf3 Be1 29. Kg4 Bd2 30. Kf5 Bc1 31. Kg6 Kf8 32. e5 Bxb2 33. Kxg5 Bxc3 34. h4 Bxd4 35. h5 Bxe5 36. g4 Bb2 37. Kf5 Kf7 38. g5 Bc1 39. g6+ Ke7 40. Ke5 b5 41. Kd4 Kd6 42. Kc3 c5 43. a3 Bg5 44. a4 bxa4 45. Kb2 Kd5 46. Ka3 Kd4 47. Kxa4 c4\n94\n\n\n4\nRated Bullet game\n1xb3os63\n-1\n1765.0\n1815.0\n60+1\nNormal\n1. e4 e6 2. f4 d5 3. e5 c5 4. Nf3 Qb6 5. c3 Nc6 6. d3 Bd7 7. Be2 Nh6 8. O-O Nf5 9. g4 Nh6 10. Kg2 Nxg4 11. h3 Nh6 12. Ng5 Nf5 13. Bg4 Nce7 14. Nd2 Ne3+ 15. Kf3 Nxd1 16. Rxd1 h6 17. Nxf7 Kxf7 18. Rf1 h5 19. Bxe6+ Bxe6 20. Kg3 Nf5+ 21. Kg2 Ne3+ 22. Kf2 Nxf1 23. Kxf1 Bxh3+\n46\n\n\n\n\n\n\n\n\ndf.hist(column='WhiteElo',bins=30,rwidth=0.9, grid=False)\n\narray([[&lt;Axes: title={'center': 'WhiteElo'}&gt;]], dtype=object)\n\n\n\n\n\n\ndf.hist(column='BlackElo',bins=30,rwidth=0.9, grid=False)\n\narray([[&lt;Axes: title={'center': 'BlackElo'}&gt;]], dtype=object)\n\n\n\n\n\n\ndf.hist(column='NumMoves',bins=30,rwidth=0.9, grid=False)\n\narray([[&lt;Axes: title={'center': 'NumMoves'}&gt;]], dtype=object)\n\n\n\n\n\n\nprint(f\"{min(df['WhiteElo'])} &lt;= White ELO &lt;= {max(df['WhiteElo'])}\\n{min(df['BlackElo'])} &lt;= Black ELO &lt;= {max(df['BlackElo'])}\")\n\n782.0 &lt;= White ELO &lt;= 2403.0\n789.0 &lt;= Black ELO &lt;= 2386.0\n\n\n\nfrom IPython.display import clear_output\nimport cairosvg\nimport io\nimport os\n\n\ndef watch_game(moves):\n    \"\"\"\n    given a string of moves displays and updates the board every time the user presses enter\n    \"\"\"\n    moves = io.StringIO(moves)\n    game = chess.pgn.read_game(moves)\n    board = game.board()\n    display(board)\n    for move in game.mainline_moves():\n        input()\n        clear_output()\n        board.push(move)\n        display(board)\n\ndef board_png_from_row(row, num_moves):\n    \"\"\"\n    given a row entry from df and the move number\n    saves a png (size: svg_size x svg_size) of the position to ./Data/PNGImages\n    \"\"\"\n    if num_moves &gt; row['NumMoves']:\n        raise(Exception(f\"num_moves exceeds maximum moves:{row['NumMoves']}\"))\n    png_path = f\"Data/PGNImages/{row['ID']}_{row['WhiteElo']}_{row['BlackElo']}_{num_moves}.png\"\n    if not os.path.isfile(png_path):\n        moves = io.StringIO(row['Moves'])\n        game = chess.pgn.read_game(moves)\n        board = game.board()\n        iter = game.mainline_moves().__iter__()\n        #+1 prevents us from generating default board\n        for _ in range(num_moves+1):\n            board.push(next(iter))\n        cairosvg.svg2png(chess.svg.board(board, coordinates=False, size=svg_size),write_to=png_path)\n    #In hindsight we really should create a method to generate all of the moves from a given row rather than calling this method on every move\n\ndef board_png_from_fen(fen):\n    \"\"\"\n    TODO\n    given a fen string\n    saves a png (size: svg_size x svg_size) of the position to ./Data/FENImages\n    \"\"\"\n    return None\n\n\ndef generate_full_game(row):\n    for i in range(row['NumMoves']):\n        board_png_from_row(row, i)\n        \ndef generate_all_games():\n    for j in range(len(df)):\n        generate_full_game(df.iloc[j])\n        print(f'completed row {j}/{len(df)}',end='\\r')\n\n\n##jupyter has issues with multiprocessing library. \n##We export the script to a .py file \n##and then run it in the notebook\n\nscript = \"\"\"import pandas as pd\nimport os\nimport cairosvg\nimport chess.pgn\nimport chess.svg\nimport io\nfrom multiprocessing import Pool\n\ndef update_chess_dtypes(df):\n\n    #converts each DataFrame column to the correct dtype\n\n    df['Event'] = df['Event'].astype(\"string\")\n    df['ID'] = df['ID'].astype(\"string\")\n    df['Result']  = df['Result'].astype(\"Int8\")\n    df['WhiteElo'] = df['WhiteElo'].astype(\"UInt16\")\n    df['BlackElo'] = df['BlackElo'].astype(\"UInt16\")\n    df['TimeControl'] = df['TimeControl'].astype(\"string\")\n    df['Termination'] = df['Termination'].astype(\"string\")\n    df['Moves'] = df['Moves'].astype(\"string\")\n    df['NumMoves'] = df['NumMoves'].astype(\"UInt16\") \n    return df\n\ndef board_png_from_row(row, num_moves):\n\n    #given a row entry from df and the move number\n    #saves a png (size: svg_size x svg_size) of the position to ./Data/PNGImages\n\n    if num_moves &gt; row['NumMoves']:\n        raise(Exception(f\"num_moves exceeds maximum moves:{row['NumMoves']}\"))\n    png_path = f\"Data/PGNImages/{row['ID']}_{row['WhiteElo']}_{row['BlackElo']}_{num_moves}.png\"\n    if not os.path.isfile(png_path):\n        moves = io.StringIO(row['Moves'])\n        game = chess.pgn.read_game(moves)\n        board = game.board()\n        iter = game.mainline_moves().__iter__()\n        #+1 prevents us from generating default board\n        for _ in range(num_moves+1):\n            board.push(next(iter))\n        cairosvg.svg2png(chess.svg.board(board, coordinates=False, size=8*10),write_to=png_path)\n\ndef generate_full_game(row):\n    for i in range(row['NumMoves']):\n        board_png_from_row(row, i)\n\ndef generate_all_games(iterrow_tuple):\n    idx = iterrow_tuple[0]\n    #print(f'row {idx}',end='\\\\r')\n    row = iterrow_tuple[1]\n    generate_full_game(row)\n    \nif __name__ == '__main__':\n    if os.path.isfile('Data/chessgames-2013-01.csv'):\n        df = pd.read_csv('Data/chessgames-2013-01.csv',index_col=0)\n        df = update_chess_dtypes(df)\n        print(f'loaded Data/chessgames-2013-01.csv into df')\n    with Pool(6) as p:\n        p.map(generate_all_games, df.iterrows())\"\"\"\nwith open(\"generate_all_games_script.py\",\"w\") as f:\n    f.write(script)\n\n\n###uncomment line below to generate images\n###WARNING this will take a long time and use ~30GB of storage\n\n#!\"generate_all_games_script.py\"\n\n###TODO is there a good way to compress these together? \n###Many files are using 5kb out of 8kb block lots of wasted space\n\n\nfrom fastai.vision.all import *\nimport torch\nimport pathlib\n\n#Data has been created time to make our model!\n\ndef get_chess_path(row):\n    return pathlib.Path(f\"Data/PGNImages/{row['ID']}_{int(row['WhiteElo'])}_{int(row['BlackElo'])}_39.png\")\ndef get_chess_images(df):\n    return df.apply(get_chess_path, axis=1).tolist()\n    \ndef white_elo(x):\n    return float(x.name[:-4].split('_')[1])\n    \nboard_block = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_items=get_chess_images,\n    splitter=RandomSplitter(valid_pct=0.125, seed=42),\n    get_y=white_elo\n    )\n\n\ndf_classical_turn_20 = df[((df['Event'] == \"Rated Classical tournament\") | (df['Event'] == \"Rated Classical game\")) & (df['NumMoves'] &gt;= 40)]\ndls = board_block.dataloaders(df_classical_turn_20)\n\ntorch.cuda.empty_cache()\nlearn = vision_learner(dls, models.resnet34, n_out=1, loss_func=mse,y_range=(700.0,2500.0))\nlearn.cuda()\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n49457.246094\n35711.085938\n00:51\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n33200.281250\n37245.757812\n00:50\n\n\n1\n30292.804688\n29608.296875\n00:50\n\n\n2\n25394.501953\n29611.537109\n00:50\n\n\n\n\n\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\ntorch.cuda.empty_cache()\nlearn = vision_learner(dls, models.resnet34, n_out=1, loss_func=mse,y_range=(700.0,2500.0))\nlearn.cuda()\nlearn.fit_one_cycle(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n219739.718750\n90923.414062\n00:49\n\n\n1\n44588.238281\n34172.554688\n00:49\n\n\n2\n34924.203125\n32391.208984\n00:50\n\n\n3\n32631.271484\n32254.845703\n00:49\n\n\n4\n31854.542969\n32142.320312\n00:49\n\n\n5\n29663.791016\n30248.066406\n00:50\n\n\n6\n28242.527344\n30415.005859\n00:54\n\n\n7\n27349.861328\n29869.423828\n00:51\n\n\n8\n26356.371094\n29817.099609\n00:47\n\n\n9\n25646.251953\n29812.654297\n00:49\n\n\n\n\n\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\npreds =learn.get_preds()\n\ndf_valid = pd.DataFrame()\ndf_valid['Path'] = [f.name for f in dls.valid_ds.items]\ndf_valid['Prediction'] = [float(x) for x in preds[0]]\ndf_valid['Target'] = [float(x) for x in preds[1]]\ndf_valid['Square Error'] = [(float(preds[0][i])-float(preds[1][i]))**2 for i in range(len(preds[0]))]\n#df_valid['Pred'] = [learn.predict(f) for f in dls.valid_ds.items]\ndf_valid.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPath\nPrediction\nTarget\nSquare Error\n\n\n\n\n0\ndr55c2w0_1378_1270_39.png\n1327.333008\n1378.0\n2567.144097\n\n\n1\npa4a4w7h_1702_1787_39.png\n1574.490479\n1702.0\n16258.678069\n\n\n2\np3vyq2t7_1754_1832_39.png\n1663.654541\n1754.0\n8162.301959\n\n\n3\n5dtunyc2_1368_1330_39.png\n1658.034546\n1368.0\n84120.037815\n\n\n4\n3vs6d2m0_1706_1600_39.png\n1512.778198\n1706.0\n37334.664675\n\n\n\n\n\n\n\n\ndf_valid.hist(column=['Target','Prediction'],bins=30,rwidth=0.9, grid=False, sharex=True, sharey=True,figsize=(15, 5))\n\narray([[&lt;Axes: title={'center': 'Target'}&gt;,\n        &lt;Axes: title={'center': 'Prediction'}&gt;]], dtype=object)\n\n\n\n\n\n\nimport seaborn as sns\nsns.lmplot(x='Target', y='Square Error', data=df_valid, fit_reg=True, order=2, line_kws={\"color\": \"C1\"})"
  },
  {
    "objectID": "posts/Chapter1/Datablocks/index.html",
    "href": "posts/Chapter1/Datablocks/index.html",
    "title": "Datablocks vs Dataloaders",
    "section": "",
    "text": "The first chapter of the fastai course goes over the building blocks of the library and how to use them to make deep learning models. The DataLoader class is a fastai replacement to the Pytorch class of the same name. This class gives us the ability to specify a wide variety of parameters to fine tune how we want to load data into our models. The book and the lecture include examples of using both ImageDataLoaders.from_name_func() and DataBlock().dataloaders() to generate a DataLoader. As my data was a collection of images I thought that I would use the ImageDataLoaders.from_name_func() method to pull in my data. I was able to load my images in without issue and the labels looked correct at first glance; however, when I went to train my model I was receiving a tensor dtype mismatch error. Somehow my labels were being converted into longs while my predictions were floats. I eventually came to realize, after looking at the DataLoader.vocab attribute, that the ImageDataLoaders.from_name_func() was generating labels for classification instead of regression. I didn’t immediately see a way to make this method generate labels for use in classification so I switched over to making a DataBlock. DataBlocks give you an extra level of customization in specifying the type of your input an output. In my case I was able to set the input to an ImageBlock and the output to a RegressionBlock. After modifying my helper functions for use with the DataBlock get_items method my DataLoader was up and running and my model was able to begin training."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there! My name is Matthew Agers. My interests include deep learning, computer vision, and audio processing. My goal is to teach myself everything that there is to know about deep learning. In this blog I will be working through the fast.ai course materials created by Jeremy Howard. I will also be posting authoritative takes on any research I find useful or inspiring, and any other projects I work on.\nI find machine learning beautiful for the same reasons I find math beautiful: because almost everyone has the ability to participate and it can be used to help us more deeply understand and interact with the natural world."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Street View City Predictor\n\n\n\n\n\n\n\nApp\n\n\nHugging Face Spaces\n\n\nfastai Chapter 2\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\nMatthew Agers\n\n\n\n\n\n\n  \n\n\n\n\nDatablocks vs Dataloaders\n\n\n\n\n\n\n\nDebugging\n\n\nfastai Chapter 1\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\nMatthew Agers\n\n\n\n\n\n\n  \n\n\n\n\nMultiprocessing In Ipython Kernel\n\n\n\n\n\n\n\nDebugging\n\n\nfastai Chapter 1\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\nMatthew Agers\n\n\n\n\n\n\n  \n\n\n\n\nLichess ELO Guesser Notebook\n\n\n\n\n\n\n\nNotebook\n\n\nfastai Chapter 1\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\nMatthew Agers\n\n\n\n\n\n\n  \n\n\n\n\nLichess ELO Guesser\n\n\n\n\n\n\n\nProject Summary\n\n\nfastai Chapter 1\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\nMatthew Agers\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Chapter1/Multiprocessing/index.html",
    "href": "posts/Chapter1/Multiprocessing/index.html",
    "title": "Multiprocessing In Ipython Kernel",
    "section": "",
    "text": "For this project I needed to generate roughly 8 million images of chess boards from the move lists of the games I had downloaded. Using the python chess library I iterated through each game and for each move created a 80x80 .png image of the board. Given the large size of the dataset and the overhead associated with creating and saving images, I needed a way to speed up this up. Multiprocessing seemed like an obvious solution, as the tasks had a simple control structure and could easily be distributed to the process pool. Using multiprocessing.Pool I set up a with statement to map the move lists from my data frame to my image generation method. I was receiving errors indicating that my previously defined methods didn’t exist, that I needed to be running from within main, or other errors that didn’t seem to make sense based on the tutorials I was following. Searching around the web for similar errors yielded many solutions that didn’t work for me. Eventually I saw a post that mentioned certain libraries in python didn’t interact correctly with the iPython kernel. Following up on this I copied my code from my Jupyter notebook to its own .py file and ran it without modifications, and sure enough it worked right off the bat. This was a pretty difficult issue to debug as the error codes I was receiving didn’t initially indicate to me that it was an issue with the kernel but rather it seemed to be an issue with the multiprocessing library. After this discovery I was able to run the script with no issues and reduced the final runtime by about 24 hours."
  },
  {
    "objectID": "posts/Chapter1/Writeup/index.html",
    "href": "posts/Chapter1/Writeup/index.html",
    "title": "Lichess ELO Guesser",
    "section": "",
    "text": "TODO\n Chapter 1 of fast.ai focuses on the fundamentals of building a model. So my project today was to build a vision learning model that predicts chess player rankings based on the position of the pieces on the board in the midgame. The model itself was only six lines of code with the help of the fastai framework, but the notebook is quite a bit larger and takes a full day to run due to the size of the data set. However, now I have the data stored on my computer and I am really excited about its potential applications for future projects.\nUltimately, the model performed pretty poorly at the tail ends of the data and tended to predict towards the average. The data was normally distributed, with the average ranking around 1500. This happens for two reasons: 1) Most people are average at chess!, but also (and more problematically), 2) Every new player on Lichess is assigned a default ranking of 1500, and there is no indication in the data set whether a given player is new or not.\nI considered attempting to work around these issues in the data, but I suspect future chapters will provide methodologies to address these sorts of discrepancies.\nNotebook Blog Post\nGithub Repo\nOnwards!"
  }
]